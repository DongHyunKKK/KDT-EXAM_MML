{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증\n",
    "- 부족한 데이터셋 및 특정 데이터에 과대적합되는 문제 해결하기 위한 방안\n",
    "- 학습 데이터셋을 일정 크기의 데이터로 n개 분리 후 1/n 검증용, 나머지는 학습용으로 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold 인스턴스 생성 => 데이터를 2개로 분할해주는 객체\n",
    "k_fold = KFold(n_splits = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([2, 3]), array([0, 1]))\n",
      "(array([0, 1]), array([2, 3]))\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분할\n",
    "datasets = k_fold.split(X)\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Weight  56 non-null     float64\n",
      " 1   Length  56 non-null     float64\n",
      " 2   Height  56 non-null     float64\n",
      " 3   Width   56 non-null     float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.9 KB\n"
     ]
    }
   ],
   "source": [
    "# perch.csv 파일 데이터 기본 5등분\n",
    "import pandas as pd\n",
    "\n",
    "perchDF = pd.read_csv('../DATA/perch3.csv')\n",
    "perchDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,\n",
      "       29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "       46, 47, 48, 49, 50, 51, 52, 53, 54, 55]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))\n",
      "1 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 23, 24, 25, 26, 27,\n",
      "       28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n",
      "       45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]), array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]))\n",
      "2 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44,\n",
      "       45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]), array([23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]))\n",
      "3 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]), array([34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]))\n",
      "4 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44]), array([45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]))\n"
     ]
    }
   ],
   "source": [
    "# perchDF 5등분\n",
    "fold_5 = KFold()\n",
    "datasets = fold_5.split(perchDF)\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    print(f'{index} => {dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (44,) (12,)\n",
      "1 => (45,) (11,)\n",
      "2 => (45,) (11,)\n",
      "3 => (45,) (11,)\n",
      "4 => (45,) (11,)\n"
     ]
    }
   ],
   "source": [
    "datasets = fold_5.split(perchDF)\n",
    "for index, (train, test) in enumerate(datasets):\n",
    "    print(f'{index} => {train.shape} {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (array([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
      "       53, 54, 55]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18]))\n",
      "1 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
      "       53, 54, 55]), array([19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "       36, 37]))\n",
      "2 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37]), array([38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
      "       55]))\n"
     ]
    }
   ],
   "source": [
    "# perchDF 3등분\n",
    "fold_3 = KFold(n_splits = 3)\n",
    "datasets = fold_3.split(perchDF)\n",
    "\n",
    "for index, dataset in enumerate(datasets):\n",
    "    print(f'{index} => {dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (37,) (19,)\n",
      "1 => (37,) (19,)\n",
      "2 => (38,) (18,)\n"
     ]
    }
   ],
   "source": [
    "datasets = fold_3.split(perchDF)\n",
    "for index, (train, test) in enumerate(datasets):\n",
    "    print(f'{index} => {train.shape} {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "irisDF = pd.read_csv('../DATA/Iris.csv')\n",
    "irisDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits = 3)\n",
    "ret = k_fold.split(irisDF[irisDF.columns[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (array([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
      "        63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "        76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "        89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "       141, 142, 143, 144, 145, 146, 147, 148, 149]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]))\n",
      "1 => (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49, 100, 101,\n",
      "       102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "       115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "       128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "       141, 142, 143, 144, 145, 146, 147, 148, 149]), array([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
      "       67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,\n",
      "       84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]))\n",
      "2 => (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
      "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
      "       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
      "       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]), array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "       113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "       126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "       139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149]))\n"
     ]
    }
   ],
   "source": [
    "for index, dataset in enumerate(ret):\n",
    "    print(f'{index} => {dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 => (100,) (50,)\n",
      "1 => (100,) (50,)\n",
      "2 => (100,) (50,)\n"
     ]
    }
   ],
   "source": [
    "ret = k_fold.split(irisDF[irisDF.columns[:-1]])\n",
    "for index, (train, test) in enumerate(ret):\n",
    "    print(f'{index} => {train.shape} {test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "versicolor    0.5\n",
      "virginica     0.5\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "setosa    1.0\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "setosa       0.5\n",
      "virginica    0.5\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "versicolor    1.0\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "setosa        0.5\n",
      "versicolor    0.5\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "virginica    1.0\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "ret = k_fold.split(irisDF[irisDF.columns[:-1]])\n",
    "\n",
    "train_score3 = []\n",
    "for p_name in ['l1', 'l2', 'elasticnet']:\n",
    "    log_model = LogisticRegression(max_iter = 1000, solver = 'liblinear', penalty = p_name)\n",
    "    for idx, (train, test) in enumerate(ret):\n",
    "        # 학습용, 테스트용 인덱스 반환\n",
    "        train_idx = train.tolist()\n",
    "        test_idx = test.tolist()\n",
    "        \n",
    "        # 인덱스에 해당하는 데이터셋 추출\n",
    "        trainDF = irisDF.iloc[train_idx]\n",
    "        testDF = irisDF.iloc[test_idx]\n",
    "        \n",
    "        print(trainDF[trainDF.columns[4]].value_counts()/trainDF.shape[0])\n",
    "        print(testDF[testDF.columns[4]].value_counts()/testDF.shape[0])\n",
    "\n",
    "        X_train = trainDF[trainDF.columns[:-1]]\n",
    "        y_train = trainDF[trainDF.columns[-1]]\n",
    "\n",
    "        X_test = testDF[testDF.columns[:-1]]\n",
    "        y_test = testDF[testDF.columns[-1]]\n",
    "\n",
    "        # 분류 모델 학습\n",
    "        log_model.fit(X_train, y_train)\n",
    "\n",
    "        # 훈련 및 검증용 성능\n",
    "        train_score = log_model.score(X_train, y_train)\n",
    "        test_score = log_model.score(X_test, y_test)\n",
    "\n",
    "        train_score3.append(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333334"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_score3)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "virginica     0.34\n",
      "setosa        0.33\n",
      "versicolor    0.33\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "setosa        0.34\n",
      "versicolor    0.34\n",
      "virginica     0.32\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "versicolor    0.34\n",
      "setosa        0.33\n",
      "virginica     0.33\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "setosa        0.34\n",
      "virginica     0.34\n",
      "versicolor    0.32\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "setosa        0.34\n",
      "versicolor    0.33\n",
      "virginica     0.33\n",
      "Name: count, dtype: float64\n",
      "species\n",
      "versicolor    0.34\n",
      "virginica     0.34\n",
      "setosa        0.32\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 타겟 데이터를 적절하게 섞어서 교차검증\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "k_fold = StratifiedKFold(n_splits = 3)\n",
    "ret = k_fold.split(irisDF[irisDF.columns[:-1]], irisDF[irisDF.columns[-1]])\n",
    "\n",
    "train_score3 = []\n",
    "for p_name in ['l1', 'l2', 'elasticnet']:\n",
    "    log_model = LogisticRegression(max_iter = 1000, solver = 'liblinear', penalty = p_name)\n",
    "    for idx, (train, test) in enumerate(ret):\n",
    "        # 학습용, 테스트용 인덱스 반환\n",
    "        train_idx = train.tolist()\n",
    "        test_idx = test.tolist()\n",
    "        \n",
    "        # 인덱스에 해당하는 데이터셋 추출\n",
    "        trainDF = irisDF.iloc[train_idx]\n",
    "        testDF = irisDF.iloc[test_idx]\n",
    "        \n",
    "        print(trainDF[trainDF.columns[4]].value_counts()/trainDF.shape[0])\n",
    "        print(testDF[testDF.columns[4]].value_counts()/testDF.shape[0])\n",
    "\n",
    "        X_train = trainDF[trainDF.columns[:-1]]\n",
    "        y_train = trainDF[trainDF.columns[-1]]\n",
    "\n",
    "        X_test = testDF[testDF.columns[:-1]]\n",
    "        y_test = testDF[testDF.columns[-1]]\n",
    "\n",
    "        # 분류 모델 학습\n",
    "        log_model.fit(X_train, y_train)\n",
    "\n",
    "        # 훈련 및 검증용 성능\n",
    "        train_score = log_model.score(X_train, y_train)\n",
    "        test_score = log_model.score(X_test, y_test)\n",
    "\n",
    "        train_score3.append(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9633333333333333"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_score3)/3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXAM_MML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
